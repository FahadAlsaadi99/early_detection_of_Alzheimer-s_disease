{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":861496,"sourceType":"datasetVersion","datasetId":457093}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D\nfrom tensorflow.keras.layers import Concatenate\nfrom tensorflow.keras.optimizers import Adam, SGD","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\nMild = glob.glob('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/MildDemented/*.*')\nModerate = glob.glob('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/ModerateDemented/*.*')\nNonDemented = glob.glob('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/NonDemented/*.*')\nVeryMild = glob.glob('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/VeryMildDemented/*.*')\n\n\ndata=[]\nlabels = []\n\nfor i in NonDemented:   \n    image=tf.keras.preprocessing.image.load_img(i, target_size= (224,224),color_mode='rgb')\n    image=np.array(image)\n    data.append(image)\n    labels.append(0)\n\nfor i in VeryMild:   \n    image=tf.keras.preprocessing.image.load_img(i, target_size= (224,224),color_mode='rgb')\n    image=np.array(image)\n    data.append(image)\n    labels.append(1)\n\nfor i in Mild:   \n    image=tf.keras.preprocessing.image.load_img(i, target_size= (224,224),color_mode='rgb')\n    image=np.array(image)\n    data.append(image)\n    labels.append(2)\n\nfor i in Moderate:   \n    image=tf.keras.preprocessing.image.load_img(i, target_size= (224,224),color_mode='rgb')\n    image=np.array(image)\n    data.append(image)\n    labels.append(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nModerate_US = Moderate\nMild_US = random.sample(Mild, 52)\nVeryMild_US = random.sample(VeryMild, 52)\nNonDemented_US = random.sample(NonDemented, 52)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\n\ndata1 =[]\nlabels1 = []\n\nfor i in NonDemented_US: \n    image=tf.keras.preprocessing.image.load_img(i,target_size= (224,224),color_mode='rgb')\n    image=np.array(image)\n    data1.append(image)\n    labels1.append(0)\n    \nfor i in VeryMild_US:   \n    image=tf.keras.preprocessing.image.load_img(i,target_size= (224,224),color_mode='rgb')\n    image=np.array(image)\n    data1.append(image)\n    labels1.append(1)\n\nfor i in Mild_US:   \n    image=tf.keras.preprocessing.image.load_img(i,target_size= (224,224),color_mode='rgb')\n    image=np.array(image)\n    data1.append(image)\n    labels1.append(2)\n\nfor i in Moderate_US:   \n    image=tf.keras.preprocessing.image.load_img(i,target_size= (224,224),color_mode='rgb')\n    image=np.array(image)\n    data1.append(image)\n    labels1.append(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\nMild_test = glob.glob('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/MildDemented/*.*')\nModerate_test = glob.glob('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/ModerateDemented/*.*')\nNonDemented_test = glob.glob('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/NonDemented/*.*')\nVeryMild_test = glob.glob('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/VeryMildDemented/*.*')\n\n\ndata_test = []\nlabels_test  = []\n\nfor i in NonDemented_test:   \n    image=tf.keras.preprocessing.image.load_img(i, target_size= (224,224),color_mode='rgb')\n    image=np.array(image)\n    data_test.append(image)\n    labels_test.append(0)\n\nfor i in VeryMild_test:   \n    image=tf.keras.preprocessing.image.load_img(i, target_size= (224,224),color_mode='rgb')\n    image=np.array(image)\n    data_test.append(image)\n    labels_test.append(1)\n\nfor i in Mild_test:   \n    image=tf.keras.preprocessing.image.load_img(i, target_size= (224,224),color_mode='rgb')\n    image=np.array(image)\n    data_test.append(image)\n    labels_test.append(2)\n\nfor i in Moderate_test:   \n    image=tf.keras.preprocessing.image.load_img(i, target_size= (224,224),color_mode='rgb')\n    image=np.array(image)\n    data_test.append(image)\n    labels_test.append(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data1 = np.array(data1)\nlabels1 = np.array(labels1)\n\ndata_test = np.array(data_test)\nlabels_test = np.array(labels_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=False,\n        fill_mode='nearest'\n    )\n\ntrain_data_gen = datagen.flow(\n    x=data1,\n    y=labels1,\n    batch_size=32,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_gen = datagen.flow(\n    x=data_test,\n    y=labels_test\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import Callback\n\nclass MetricsCallback(Callback):\n    def __init__(self, validation_data):\n        self.validation_data = validation_data\n\n    def on_epoch_end(self, epoch, logs=None):\n        x_val, y_val = self.validation_data\n        y_pred = np.argmax(self.model.predict(x_val), axis=1)\n\n        true_positives = np.sum(np.logical_and(y_val == 1, y_pred == 1))\n        false_positives = np.sum(np.logical_and(y_val == 0, y_pred == 1))\n\n        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n        recall = true_positives / np.sum(y_val == 1) if np.sum(y_val == 1) > 0 else 0\n\n        print(f'\\nPrecision: {precision:.4f} - Recall: {recall:.4f}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n\nmodel = Sequential([\n    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n    \n    Conv2D(64, (3, 3), activation='relu', padding='same'),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n    \n    Conv2D(128, (3, 3), activation='relu', padding='same'),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n\n    Conv2D(256, (3, 3), activation='relu', padding='same'),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n\n    Flatten(),\n    Dense(256, activation='relu'),\n    Dropout(0.5),\n    BatchNormalization(),\n\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    BatchNormalization(),\n\n    Dense(4, activation='softmax')\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(train_data_gen.x,train_data_gen.y ,batch_size=16, epochs=10,validation_data=test_data_gen, callbacks=[MetricsCallback((test_data_gen.x, test_data_gen.y))])\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}