{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":861496,"sourceType":"datasetVersion","datasetId":457093}],"dockerImageVersionId":30558,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport glob\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train'):\n #   for filename in filenames:\n  #      print(os.path.join(dirname, filename))\nimport os\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D\nfrom tensorflow.keras.layers import Concatenate\nfrom tensorflow.keras.optimizers import Adam, SGD\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Mild = glob.glob('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/MildDemented/*.*')\nModerate = glob.glob('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/ModerateDemented/*.*')\nNonDemented = glob.glob('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/NonDemented/*.*')\nVeryMild = glob.glob('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/VeryMildDemented/*.*')\n\n\ndata = []\nlabels = []\n\nfor i in NonDemented:   \n    image=tf.keras.preprocessing.image.load_img(i, target_size= (224,224))\n    image=np.array(image)\n    data.append(image)\n    labels.append(0)\n\nfor i in VeryMild:   \n    image=tf.keras.preprocessing.image.load_img(i, target_size= (224,224))\n    image=np.array(image)\n    data.append(image)\n    labels.append(1)\n\nfor i in Mild:   \n    image=tf.keras.preprocessing.image.load_img(i, target_size= (224,224))\n    image=np.array(image)\n    data.append(image)\n    labels.append(2)\n\nfor i in Moderate:   \n    image=tf.keras.preprocessing.image.load_img(i, target_size= (224,224))\n    image=np.array(image)\n    data.append(image)\n    labels.append(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\nMild_test = glob.glob('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/MildDemented/*.*')\nModerate_test = glob.glob('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/ModerateDemented/*.*')\nNonDemented_test = glob.glob('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/NonDemented/*.*')\nVeryMild_test = glob.glob('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/VeryMildDemented/*.*')\n\n\ndata_test = []\nlabels_test  = []\n\nfor i in NonDemented_test:   \n    image=tf.keras.preprocessing.image.load_img(i, target_size= (224,224),grayscale=False)\n    image=np.array(image)\n    data_test.append(image)\n    labels_test.append(0)\n\nfor i in VeryMild_test:   \n    image=tf.keras.preprocessing.image.load_img(i, target_size= (224,224),grayscale=False)\n    image=np.array(image)\n    data_test.append(image)\n    labels_test.append(1)\n\nfor i in Mild_test:   \n    image=tf.keras.preprocessing.image.load_img(i, target_size= (224,224),grayscale=False)\n    image=np.array(image)\n    data_test.append(image)\n    labels_test.append(2)\n\nfor i in Moderate_test:   \n    image=tf.keras.preprocessing.image.load_img(i, target_size= (224,224),grayscale=False)\n    image=np.array(image)\n    data_test.append(image)\n    labels_test.append(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = np.array(data)\nlabels = np.array(labels)\n\ndata_test = np.array(data_test)\nlabels_test = np.array(labels_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(rescale=1./255,\n                            rotation_range=45,\n                            width_shift_range=.15,\n                            height_shift_range=.15,\n                            horizontal_flip=False)\n\ntrain_data_gen = datagen.flow(\n    x=data,\n    y=labels,\n    batch_size=64,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_gen = datagen.flow(\n    x=data_test,\n    y=labels_test\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Layer\n\nclass SelfAttention(Layer):\n    def __init__(self):\n        super(SelfAttention, self).__init__()\n\n    def build(self, input_shape):\n        self.W_q = self.add_weight(shape=(input_shape[-1], input_shape[-1]),\n                                  initializer='uniform',\n                                  trainable=True)\n        self.W_k = self.add_weight(shape=(input_shape[-1], input_shape[-1]),\n                                  initializer='uniform',\n                                  trainable=True)\n        super(SelfAttention, self).build(input_shape)\n\n    def call(self, x):\n        Q = tf.matmul(x, self.W_q)\n        K = tf.matmul(x, self.W_k)\n        V = x\n        attention_weights = tf.nn.softmax(tf.matmul(Q, K, transpose_b=True), axis=-1)\n        output = tf.matmul(attention_weights, V)\n        return output\n\n# Create the model with the Self-Attention Layer\nmodel = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n    MaxPooling2D((2, 2)),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    SelfAttention(),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(4, activation='softmax')\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(train_data_gen, batch_size=32, epochs=10, validation_data=test_data_gen)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}